{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook 1: Multimodal Data Representation\n",
    "========================================\n",
    "\n",
    "[Click to view on Google Colab](https://colab.research.google.com/drive/1OfR2NZKtmpfksvJXDiOaxyaPGW-10P73?usp=sharing)\n",
    "\n",
    "This script demonstrates how different modalities (text, image, audio) are \n",
    "represented as data in multimodal AI systems. We'll explore the raw formats,\n",
    "data types, shapes, and basic properties of each modality using dummy data.\n",
    "\n",
    "Learning Objectives:\n",
    "- Understand how different modalities are stored as data\n",
    "- Learn about data types and shapes for each modality\n",
    "- Explore basic properties and characteristics of multimodal data\n",
    "- See how metadata accompanies each modality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Users/ishandutta/miniconda3/envs/gs/lib/python3.10/site-packages (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy    \n",
    "\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Tuple, Any"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Data Representation\n",
    "  \n",
    "**Understanding How Text is Stored and Analyzed in AI Systems**  \n",
    "\n",
    "Text data forms the foundation of many AI applications, but understanding how computers actually store and process text is crucial for multimodal AI development. The TextDataRepresentation class reveals the fundamental characteristics that make text unique among data modalities.  \n",
    "\n",
    "**Key Concepts Explored:**    \n",
    "1. **Text as Variable-Length Data**  \n",
    "Unlike images with fixed dimensions, text naturally varies in length from single words to entire documents\n",
    "This variability creates challenges for batch processing and memory allocation\n",
    "Different text samples can have vastly different computational requirements\n",
    "2. **Character Encoding and Memory Usage**  \n",
    "Text uses UTF-8 encoding to support international characters and emojis\n",
    "Memory usage scales with text length and character complexity\n",
    "Special characters and emojis consume more bytes than standard ASCII characters\n",
    "3. **Text Properties and Metadata**  \n",
    "Character count vs. word count provides different perspectives on text complexity\n",
    "Special character detection helps identify preprocessing needs\n",
    "Data type information reveals how programming languages handle text internally\n",
    "4. **Multilingual and Special Character Handling**  \n",
    "Modern AI systems must handle multiple languages seamlessly\n",
    "Emojis and symbols carry semantic meaning in contemporary communication\n",
    "Unicode support is essential for global AI applications\n",
    "  \n",
    "**Learning Outcomes:**  \n",
    "Learners will understand that text, while appearing simple, has complex underlying representations that affect how AI systems process language. This foundation is essential for understanding why text preprocessing is necessary and how text interacts with other modalities in multimodal systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MULTIMODAL AI - DATA REPRESENTATION DEMONSTRATION\n",
      "=======================================================\n",
      "Timestamp: 2025-08-16 15:52:55\n",
      "\n",
      "PART 1: TEXT DATA REPRESENTATION\n",
      "===================================\n",
      "=== Text Modality Representation ===\n",
      "\n",
      "1. Raw Text Data Samples:\n",
      "   short_text: 'Hello world!'\n",
      "   medium_text: 'This is a sample sentence for multimodal AI demons...'\n",
      "   long_text: 'This is a longer text sample that demonstrates how...'\n",
      "   multilingual: 'Hello, Bonjour, Hola, こんにちは'\n",
      "   special_chars: 'Text with numbers: 123, symbols: @#$%, and emojis:...'\n",
      "\n",
      "2. Text Data Analysis:\n",
      "\n",
      "   short_text:\n",
      "     character_count: 12\n",
      "     word_count: 2\n",
      "     data_type: str\n",
      "     encoding: UTF-8\n",
      "     contains_special_chars: True\n",
      "     memory_size_bytes: 12\n",
      "\n",
      "   medium_text:\n",
      "     character_count: 58\n",
      "     word_count: 9\n",
      "     data_type: str\n",
      "     encoding: UTF-8\n",
      "     contains_special_chars: True\n",
      "     memory_size_bytes: 58\n",
      "\n",
      "   long_text:\n",
      "     character_count: 216\n",
      "     word_count: 25\n",
      "     data_type: str\n",
      "     encoding: UTF-8\n",
      "     contains_special_chars: True\n",
      "     memory_size_bytes: 216\n",
      "\n",
      "   multilingual:\n",
      "     character_count: 27\n",
      "     word_count: 4\n",
      "     data_type: str\n",
      "     encoding: UTF-8\n",
      "     contains_special_chars: True\n",
      "     memory_size_bytes: 37\n",
      "\n",
      "   special_chars:\n",
      "     character_count: 53\n",
      "     word_count: 9\n",
      "     data_type: str\n",
      "     encoding: UTF-8\n",
      "     contains_special_chars: True\n",
      "     memory_size_bytes: 59\n",
      "\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class TextDataRepresentation:\n",
    "    \"\"\"\n",
    "    Handles text data representation and provides insights into text properties\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.name = \"Text Modality\"\n",
    "        \n",
    "    def create_dummy_text_data(self) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Creates dummy text data with various formats and properties\n",
    "        \n",
    "        Returns:\n",
    "            Dict containing text samples with metadata\n",
    "        \"\"\"\n",
    "        dummy_texts = {\n",
    "            'short_text': \"Hello world!\",\n",
    "            'medium_text': \"This is a sample sentence for multimodal AI demonstration.\",\n",
    "            'long_text': \"\"\"This is a longer text sample that demonstrates how text data \n",
    "                           can vary significantly in length. Multimodal AI systems need to \n",
    "                           handle such variations effectively.\"\"\",\n",
    "            'multilingual': \"Hello, Bonjour, Hola, こんにちは\",\n",
    "            'special_chars': \"Text with numbers: 123, symbols: @#$%, and emojis: 😊🚀\"\n",
    "        }\n",
    "        \n",
    "        return dummy_texts\n",
    "    \n",
    "    def analyze_text_properties(self, text_data: Dict[str, str]) -> Dict[str, Dict]:\n",
    "        \"\"\"\n",
    "        Analyzes basic properties of text data\n",
    "        \n",
    "        Args:\n",
    "            text_data: Dictionary of text samples\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing analysis results for each text sample\n",
    "        \"\"\"\n",
    "        analysis = {}\n",
    "        \n",
    "        for key, text in text_data.items():\n",
    "            analysis[key] = {\n",
    "                'character_count': len(text),\n",
    "                'word_count': len(text.split()),\n",
    "                'data_type': type(text).__name__,\n",
    "                'encoding': 'UTF-8',\n",
    "                'contains_special_chars': any(not c.isalnum() and not c.isspace() for c in text),\n",
    "                'memory_size_bytes': len(text.encode('utf-8'))\n",
    "            }\n",
    "            \n",
    "        return analysis\n",
    "    \n",
    "    def demonstrate_text_representation(self):\n",
    "        \"\"\"\n",
    "        Main demonstration function for text data representation\n",
    "        \"\"\"\n",
    "        print(f\"=== {self.name} Representation ===\\n\")\n",
    "        \n",
    "        # Create dummy data\n",
    "        text_data = self.create_dummy_text_data()\n",
    "        \n",
    "        print(\"1. Raw Text Data Samples:\")\n",
    "        for key, text in text_data.items():\n",
    "            print(f\"   {key}: '{text[:50]}{'...' if len(text) > 50 else ''}'\")\n",
    "        \n",
    "        print(\"\\n2. Text Data Analysis:\")\n",
    "        analysis = self.analyze_text_properties(text_data)\n",
    "        \n",
    "        for key, props in analysis.items():\n",
    "            print(f\"\\n   {key}:\")\n",
    "            for prop, value in props.items():\n",
    "                print(f\"     {prop}: {value}\")\n",
    "        \n",
    "        return text_data, analysis\n",
    "    \n",
    "print(\"MULTIMODAL AI - DATA REPRESENTATION DEMONSTRATION\")\n",
    "print(\"=\" * 55)\n",
    "print(f\"Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "\n",
    "print(\"PART 1: TEXT DATA REPRESENTATION\")\n",
    "print(\"=\" * 35)\n",
    "text_handler = TextDataRepresentation()\n",
    "text_data, text_analysis = text_handler.demonstrate_text_representation()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Data Representation\n",
    "\n",
    "**From Pixels to Numerical Arrays: Image Data Fundamentals**  \n",
    "\n",
    "Images represent one of the most data-intensive modalities in AI systems. The ImageDataRepresentation class demonstrates how visual information is converted into numerical arrays and the various factors that affect image data characteristics.\n",
    "\n",
    "**Key Concepts Explored:**    \n",
    "1. **Dimensional Complexity**  \n",
    "Images are multi-dimensional arrays with height, width, and channel dimensions\n",
    "Different color spaces (grayscale, RGB, RGBA) affect data structure and memory usage\n",
    "Image resolution directly impacts computational requirements and memory consumption\n",
    "2. **Pixel Value Characteristics**  \n",
    "Pixel values typically range from 0-255 for 8-bit images\n",
    "Statistical properties (min, max, mean) provide insights into image characteristics\n",
    "Data types (uint8, float32) affect precision and memory usage\n",
    "3. **Memory and Storage Considerations**  \n",
    "Images consume significantly more memory than text data\n",
    "Higher resolution and more channels exponentially increase storage requirements\n",
    "Memory usage directly impacts batch sizes and processing speed\n",
    "4. **Color Space Variations**  \n",
    "Grayscale images contain intensity information only\n",
    "RGB images capture full color information across three channels\n",
    "RGBA images include transparency information, adding complexity\n",
    "5. **Spatial Relationships**  \n",
    "Unlike text sequences, images have 2D spatial relationships between pixels\n",
    "Neighboring pixels often contain related information\n",
    "Spatial structure is crucial for visual understanding\n",
    "\n",
    "**Learning Outcomes:**  \n",
    "Learners will appreciate the high-dimensional nature of image data, understand why images require substantial computational resources, and recognize how image characteristics affect AI system design. This knowledge is fundamental for understanding image-text and image-audio interactions in multimodal systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PART 2: IMAGE DATA REPRESENTATION\n",
      "===================================\n",
      "=== Image Modality Representation ===\n",
      "\n",
      "1. Image Data Samples:\n",
      "   grayscale_small: grayscale image\n",
      "   rgb_medium: RGB image\n",
      "   rgba_large: RGBA image\n",
      "   high_res_rgb: RGB image\n",
      "\n",
      "2. Image Data Analysis:\n",
      "\n",
      "   grayscale_small:\n",
      "     shape: (64, 64)\n",
      "     dimensions: 2\n",
      "     data_type: uint8\n",
      "     total_pixels: 4096\n",
      "     memory_size_bytes: 4096\n",
      "     min_value: 0\n",
      "     max_value: 255\n",
      "     mean_value: 127.03759765625\n",
      "     channels: 1\n",
      "     color_space: grayscale\n",
      "\n",
      "   rgb_medium:\n",
      "     shape: (128, 128, 3)\n",
      "     dimensions: 3\n",
      "     data_type: uint8\n",
      "     total_pixels: 49152\n",
      "     memory_size_bytes: 49152\n",
      "     min_value: 0\n",
      "     max_value: 255\n",
      "     mean_value: 127.306640625\n",
      "     channels: 3\n",
      "     color_space: RGB\n",
      "\n",
      "   rgba_large:\n",
      "     shape: (256, 256, 4)\n",
      "     dimensions: 3\n",
      "     data_type: uint8\n",
      "     total_pixels: 262144\n",
      "     memory_size_bytes: 262144\n",
      "     min_value: 0\n",
      "     max_value: 255\n",
      "     mean_value: 127.72173309326172\n",
      "     channels: 4\n",
      "     color_space: RGBA\n",
      "\n",
      "   high_res_rgb:\n",
      "     shape: (512, 512, 3)\n",
      "     dimensions: 3\n",
      "     data_type: uint8\n",
      "     total_pixels: 786432\n",
      "     memory_size_bytes: 786432\n",
      "     min_value: 0\n",
      "     max_value: 255\n",
      "     mean_value: 127.4416618347168\n",
      "     channels: 3\n",
      "     color_space: RGB\n",
      "\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class ImageDataRepresentation:\n",
    "    \"\"\"\n",
    "    Handles image data representation and provides insights into image properties\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.name = \"Image Modality\"\n",
    "        \n",
    "    def create_dummy_image_data(self) -> Dict[str, Dict]:\n",
    "        \"\"\"\n",
    "        Creates dummy image data with various formats and properties\n",
    "        \n",
    "        Returns:\n",
    "            Dict containing image arrays with metadata\n",
    "        \"\"\"\n",
    "        dummy_images = {\n",
    "            'grayscale_small': {\n",
    "                'data': np.random.randint(0, 256, (64, 64), dtype=np.uint8),\n",
    "                'channels': 1,\n",
    "                'color_space': 'grayscale'\n",
    "            },\n",
    "            'rgb_medium': {\n",
    "                'data': np.random.randint(0, 256, (128, 128, 3), dtype=np.uint8),\n",
    "                'channels': 3,\n",
    "                'color_space': 'RGB'\n",
    "            },\n",
    "            'rgba_large': {\n",
    "                'data': np.random.randint(0, 256, (256, 256, 4), dtype=np.uint8),\n",
    "                'channels': 4,\n",
    "                'color_space': 'RGBA'\n",
    "            },\n",
    "            'high_res_rgb': {\n",
    "                'data': np.random.randint(0, 256, (512, 512, 3), dtype=np.uint8),\n",
    "                'channels': 3,\n",
    "                'color_space': 'RGB'\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        return dummy_images\n",
    "    \n",
    "    def analyze_image_properties(self, image_data: Dict[str, Dict]) -> Dict[str, Dict]:\n",
    "        \"\"\"\n",
    "        Analyzes basic properties of image data\n",
    "        \n",
    "        Args:\n",
    "            image_data: Dictionary of image samples with metadata\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing analysis results for each image\n",
    "        \"\"\"\n",
    "        analysis = {}\n",
    "        \n",
    "        for key, img_info in image_data.items():\n",
    "            img_array = img_info['data']\n",
    "            analysis[key] = {\n",
    "                'shape': img_array.shape,\n",
    "                'dimensions': len(img_array.shape),\n",
    "                'data_type': img_array.dtype,\n",
    "                'total_pixels': img_array.size,\n",
    "                'memory_size_bytes': img_array.nbytes,\n",
    "                'min_value': int(img_array.min()),\n",
    "                'max_value': int(img_array.max()),\n",
    "                'mean_value': float(np.mean(img_array)),\n",
    "                'channels': img_info['channels'],\n",
    "                'color_space': img_info['color_space']\n",
    "            }\n",
    "            \n",
    "        return analysis\n",
    "    \n",
    "    def demonstrate_image_representation(self):\n",
    "        \"\"\"\n",
    "        Main demonstration function for image data representation\n",
    "        \"\"\"\n",
    "        print(f\"=== {self.name} Representation ===\\n\")\n",
    "        \n",
    "        # Create dummy data\n",
    "        image_data = self.create_dummy_image_data()\n",
    "        \n",
    "        print(\"1. Image Data Samples:\")\n",
    "        for key, img_info in image_data.items():\n",
    "            print(f\"   {key}: {img_info['color_space']} image\")\n",
    "        \n",
    "        print(\"\\n2. Image Data Analysis:\")\n",
    "        analysis = self.analyze_image_properties(image_data)\n",
    "        \n",
    "        for key, props in analysis.items():\n",
    "            print(f\"\\n   {key}:\")\n",
    "            for prop, value in props.items():\n",
    "                print(f\"     {prop}: {value}\")\n",
    "        \n",
    "        return image_data, analysis\n",
    "    \n",
    "print(\"PART 2: IMAGE DATA REPRESENTATION\")\n",
    "print(\"=\" * 35)\n",
    "image_handler = ImageDataRepresentation()\n",
    "image_data, image_analysis = image_handler.demonstrate_image_representation()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audio Data Representation\n",
    "\n",
    "**Temporal Signals and Spectral Information: Audio Data Fundamentals**  \n",
    "\n",
    "Audio data introduces temporal complexity that differs from both text sequences and spatial images. The AudioDataRepresentation class explores how continuous sound waves are digitized and the various factors that characterize audio data.\n",
    "\n",
    "**Key Concepts Explored:**    \n",
    "1. **Temporal Data Characteristics**  \n",
    "Audio is inherently time-series data with temporal dependencies\n",
    "Sample rates determine the fidelity of audio capture (16kHz for speech, 44.1kHz for music)\n",
    "Duration directly affects data size and processing requirements\n",
    "2. **Channel Configuration Impact**  \n",
    "Mono audio contains single-channel information, suitable for speech processing\n",
    "Stereo audio captures spatial audio information but doubles data requirements\n",
    "Channel configuration affects both storage needs and processing complexity\n",
    "3. **Amplitude and Dynamic Range**  \n",
    "Audio amplitudes typically range from -1.0 to 1.0 in normalized form\n",
    "RMS amplitude provides insight into average signal energy\n",
    "Dynamic range indicates the difference between loudest and quietest parts\n",
    "4. **Sample Rate Considerations**  \n",
    "Different applications require different sample rates (16kHz for speech, 48kHz for professional audio)\n",
    "Higher sample rates capture more frequency information but increase data size\n",
    "Sample rate affects the maximum frequency that can be accurately represented\n",
    "5. **Memory Usage Patterns**  \n",
    "Audio memory usage scales with duration, sample rate, and channel count\n",
    "Long-duration, high-quality stereo audio can consume substantial memory\n",
    "Temporal nature means audio data grows linearly with recording time\n",
    "6. **Quality vs. Efficiency Trade-offs**  \n",
    "Higher sample rates and longer durations improve quality but increase computational load\n",
    "Different use cases (speech recognition vs. music analysis) have different quality requirements\n",
    "Balancing audio quality with processing efficiency is crucial for real-time applications\n",
    "\n",
    "**Learning Outcomes:**  \n",
    "Learners will understand the temporal nature of audio data, appreciate the relationship between audio quality and computational requirements, and recognize how audio characteristics differ from text and image data. This foundation prepares them for understanding audio-visual synchronization and audio-text alignment in multimodal systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PART 3: AUDIO DATA REPRESENTATION\n",
      "===================================\n",
      "=== Audio Modality Representation ===\n",
      "\n",
      "1. Audio Data Samples:\n",
      "   short_mono: 1.0s mono at 16000Hz\n",
      "   medium_stereo: 3.0s stereo at 44100Hz\n",
      "   long_mono: 10.0s mono at 22050Hz\n",
      "   high_quality_stereo: 5.0s stereo at 48000Hz\n",
      "\n",
      "2. Audio Data Analysis:\n",
      "\n",
      "   short_mono:\n",
      "     shape: (16000,)\n",
      "     data_type: float64\n",
      "     sample_rate: 16000\n",
      "     channels: 1\n",
      "     duration_seconds: 1.0000\n",
      "     total_samples: 16000\n",
      "     memory_size_bytes: 128000\n",
      "     min_amplitude: -0.9998\n",
      "     max_amplitude: 0.9999\n",
      "     rms_amplitude: 0.5760\n",
      "     dynamic_range: 1.9997\n",
      "\n",
      "   medium_stereo:\n",
      "     shape: (132300, 2)\n",
      "     data_type: float64\n",
      "     sample_rate: 44100\n",
      "     channels: 2\n",
      "     duration_seconds: 3.0000\n",
      "     total_samples: 264600\n",
      "     memory_size_bytes: 2116800\n",
      "     min_amplitude: -1.0000\n",
      "     max_amplitude: 1.0000\n",
      "     rms_amplitude: 0.5767\n",
      "     dynamic_range: 2.0000\n",
      "\n",
      "   long_mono:\n",
      "     shape: (220500,)\n",
      "     data_type: float64\n",
      "     sample_rate: 22050\n",
      "     channels: 1\n",
      "     duration_seconds: 10.0000\n",
      "     total_samples: 220500\n",
      "     memory_size_bytes: 1764000\n",
      "     min_amplitude: -1.0000\n",
      "     max_amplitude: 1.0000\n",
      "     rms_amplitude: 0.5776\n",
      "     dynamic_range: 2.0000\n",
      "\n",
      "   high_quality_stereo:\n",
      "     shape: (240000, 2)\n",
      "     data_type: float64\n",
      "     sample_rate: 48000\n",
      "     channels: 2\n",
      "     duration_seconds: 5.0000\n",
      "     total_samples: 480000\n",
      "     memory_size_bytes: 3840000\n",
      "     min_amplitude: -1.0000\n",
      "     max_amplitude: 1.0000\n",
      "     rms_amplitude: 0.5778\n",
      "     dynamic_range: 2.0000\n",
      "\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class AudioDataRepresentation:\n",
    "    \"\"\"\n",
    "    Handles audio data representation and provides insights into audio properties\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.name = \"Audio Modality\"\n",
    "        \n",
    "    def create_dummy_audio_data(self) -> Dict[str, Dict]:\n",
    "        \"\"\"\n",
    "        Creates dummy audio data with various formats and properties\n",
    "        \n",
    "        Returns:\n",
    "            Dict containing audio arrays with metadata\n",
    "        \"\"\"\n",
    "        dummy_audio = {\n",
    "            # Low-quality mono audio - typical for voice recordings, phone calls, or basic speech recognition\n",
    "            # Example: voice commands, phone conversations, simple audio notifications\n",
    "            'short_mono': {\n",
    "                'data': np.random.uniform(-1.0, 1.0, 16000),  # 1 second at 16kHz\n",
    "                'sample_rate': 16000,\n",
    "                'channels': 1,\n",
    "                'duration_seconds': 1.0\n",
    "            },\n",
    "            # CD-quality stereo audio - standard for music playback and high-quality audio content\n",
    "            # Example: music streaming, podcast episodes, audio books with background music\n",
    "            'medium_stereo': {\n",
    "                'data': np.random.uniform(-1.0, 1.0, (44100 * 3, 2)),  # 3 seconds stereo at 44.1kHz\n",
    "                'sample_rate': 44100,\n",
    "                'channels': 2,\n",
    "                'duration_seconds': 3.0\n",
    "            },\n",
    "            # Lower sample rate mono - common for speech processing and older digital audio\n",
    "            # Example: compressed voice recordings, legacy audio systems, speech synthesis\n",
    "            'long_mono': {\n",
    "                'data': np.random.uniform(-1.0, 1.0, 22050 * 10),  # 10 seconds at 22.05kHz\n",
    "                'sample_rate': 22050,\n",
    "                'channels': 1,\n",
    "                'duration_seconds': 10.0\n",
    "            },\n",
    "            # Professional/studio quality stereo - used in audio production and high-end applications\n",
    "            # Example: professional music recording, film audio, broadcast quality content\n",
    "            'high_quality_stereo': {\n",
    "                'data': np.random.uniform(-1.0, 1.0, (48000 * 5, 2)),  # 5 seconds stereo at 48kHz\n",
    "                'sample_rate': 48000,\n",
    "                'channels': 2,\n",
    "                'duration_seconds': 5.0\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        return dummy_audio\n",
    "    \n",
    "    def analyze_audio_properties(self, audio_data: Dict[str, Dict]) -> Dict[str, Dict]:\n",
    "        \"\"\"\n",
    "        Analyzes basic properties of audio data\n",
    "        \n",
    "        Args:\n",
    "            audio_data: Dictionary of audio samples with metadata\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing analysis results for each audio sample\n",
    "        \"\"\"\n",
    "        analysis = {}\n",
    "        \n",
    "        for key, audio_info in audio_data.items():\n",
    "            audio_array = audio_info['data']\n",
    "            analysis[key] = {\n",
    "                'shape': audio_array.shape,\n",
    "                'data_type': audio_array.dtype,\n",
    "                'sample_rate': audio_info['sample_rate'],\n",
    "                'channels': audio_info['channels'],\n",
    "                'duration_seconds': audio_info['duration_seconds'],\n",
    "                'total_samples': audio_array.size,\n",
    "                'memory_size_bytes': audio_array.nbytes,\n",
    "                'min_amplitude': float(audio_array.min()),\n",
    "                'max_amplitude': float(audio_array.max()),\n",
    "                'rms_amplitude': float(np.sqrt(np.mean(audio_array**2))),\n",
    "                'dynamic_range': float(audio_array.max() - audio_array.min())\n",
    "            }\n",
    "            \n",
    "        return analysis\n",
    "    \n",
    "    def demonstrate_audio_representation(self):\n",
    "        \"\"\"\n",
    "        Main demonstration function for audio data representation\n",
    "        \"\"\"\n",
    "        print(f\"=== {self.name} Representation ===\\n\")\n",
    "        \n",
    "        # Create dummy data\n",
    "        audio_data = self.create_dummy_audio_data()\n",
    "        \n",
    "        print(\"1. Audio Data Samples:\")\n",
    "        for key, audio_info in audio_data.items():\n",
    "            channels_str = \"mono\" if audio_info['channels'] == 1 else \"stereo\"\n",
    "            print(f\"   {key}: {audio_info['duration_seconds']}s {channels_str} at {audio_info['sample_rate']}Hz\")\n",
    "        \n",
    "        print(\"\\n2. Audio Data Analysis:\")\n",
    "        analysis = self.analyze_audio_properties(audio_data)\n",
    "        \n",
    "        for key, props in analysis.items():\n",
    "            print(f\"\\n   {key}:\")\n",
    "            for prop, value in props.items():\n",
    "                if isinstance(value, float):\n",
    "                    print(f\"     {prop}: {value:.4f}\")\n",
    "                else:\n",
    "                    print(f\"     {prop}: {value}\")\n",
    "        \n",
    "        return audio_data, analysis\n",
    "    \n",
    "print(\"PART 3: AUDIO DATA REPRESENTATION\")\n",
    "print(\"=\" * 35)\n",
    "audio_handler = AudioDataRepresentation()\n",
    "audio_data, audio_analysis = audio_handler.demonstrate_audio_representation()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multimodal Data Comparison\n",
    "\n",
    "**Cross-Modal Analysis: Understanding Data Modality Differences**  \n",
    "\n",
    "The comparison section synthesizes insights from all three modalities, highlighting the fundamental differences that make multimodal AI both challenging and powerful. Understanding these differences is crucial for designing effective multimodal systems.\n",
    "\n",
    "**Key Concepts Explored:**    \n",
    "1. **Memory Usage Disparities**  \n",
    "Text data is extremely memory-efficient, measured in bytes to kilobytes\n",
    "Image data requires moderate to high memory, measured in kilobytes to megabytes\n",
    "Audio data falls between text and images, with usage depending on duration and quality\n",
    "These disparities affect system design, batch processing, and hardware requirements\n",
    "2. **Data Type Fundamentals**  \n",
    "Text: Discrete symbolic data with semantic relationships between symbols\n",
    "Images: Continuous numerical data with spatial relationships between pixels\n",
    "Audio: Continuous temporal data with frequency and phase relationships\n",
    "3. **Structural Characteristics**  \n",
    "Text: Variable-length sequences with discrete tokens and semantic dependencies\n",
    "Images: Fixed-dimensional grids with spatial locality and visual patterns\n",
    "Audio: Time-series data with temporal dependencies and spectral characteristics\n",
    "4. **Processing Implications**  \n",
    "Each modality requires different preprocessing approaches\n",
    "Memory allocation strategies must account for modality-specific requirements\n",
    "Computational complexity varies significantly across modalities\n",
    "5. **Information Density Variations**  \n",
    "Text packs semantic information efficiently in compact representations\n",
    "Images contain rich visual information but require large storage\n",
    "Audio captures temporal and spectral information with moderate storage needs\n",
    "6. **Scalability Considerations**  \n",
    "Text scales well with vocabulary size and sequence length\n",
    "Images scale quadratically with resolution increases\n",
    "Audio scales linearly with duration and sample rate\n",
    "  \n",
    "**Learning Outcomes:**  \n",
    "Learners will understand why multimodal AI systems are complex, appreciate the engineering challenges of combining different data types, and recognize the trade-offs involved in multimodal system design. This comparative understanding provides the foundation for exploring how these different modalities can be effectively combined and how their unique characteristics can complement each other in multimodal AI applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PART 4: MULTIMODAL DATA COMPARISON\n",
      "===================================\n",
      "=== Multimodal Comparison ===\n",
      "\n",
      "1. Memory Usage Comparison (bytes):\n",
      "   Text modality:\n",
      "     short_text: 12\n",
      "     medium_text: 58\n",
      "     long_text: 216\n",
      "     multilingual: 37\n",
      "     special_chars: 59\n",
      "   Image modality:\n",
      "     grayscale_small: 4096\n",
      "     rgb_medium: 49152\n",
      "     rgba_large: 262144\n",
      "     high_res_rgb: 786432\n",
      "   Audio modality:\n",
      "     short_mono: 128000\n",
      "     medium_stereo: 2116800\n",
      "     long_mono: 1764000\n",
      "     high_quality_stereo: 3840000\n",
      "\n",
      "2. Data Type Summary:\n",
      "   Text: String/Unicode (variable length)\n",
      "   Image: Numerical arrays (fixed dimensions)\n",
      "   Audio: Numerical arrays (time-series)\n",
      "\n",
      "3. Key Characteristics:\n",
      "   Text:\n",
      "     - Discrete symbols/tokens\n",
      "     - Variable length sequences\n",
      "     - Semantic meaning in combinations\n",
      "   Image:\n",
      "     - Continuous pixel values\n",
      "     - Spatial relationships important\n",
      "     - Fixed dimensional grids\n",
      "   Audio:\n",
      "     - Continuous amplitude values\n",
      "     - Temporal relationships important\n",
      "     - Time-series data\n",
      "\n",
      "============================================================\n",
      "DEMONSTRATION COMPLETE\n",
      "\n",
      "Key Takeaways:\n",
      "- Each modality has unique data representation characteristics\n",
      "- Memory requirements vary significantly across modalities\n",
      "- Data types and structures differ fundamentally\n",
      "- Understanding these differences is crucial for multimodal AI\n"
     ]
    }
   ],
   "source": [
    "class MultimodalDataComparison:\n",
    "    \"\"\"\n",
    "    Compares and contrasts different modalities\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.name = \"Multimodal Comparison\"\n",
    "    \n",
    "    def compare_modalities(self, text_analysis: Dict, image_analysis: Dict, audio_analysis: Dict):\n",
    "        \"\"\"\n",
    "        Compares properties across different modalities\n",
    "        \n",
    "        Args:\n",
    "            text_analysis: Analysis results from text data\n",
    "            image_analysis: Analysis results from image data  \n",
    "            audio_analysis: Analysis results from audio data\n",
    "        \"\"\"\n",
    "        print(f\"=== {self.name} ===\\n\")\n",
    "        \n",
    "        print(\"1. Memory Usage Comparison (bytes):\")\n",
    "        print(\"   Text modality:\")\n",
    "        for key, props in text_analysis.items():\n",
    "            print(f\"     {key}: {props['memory_size_bytes']}\")\n",
    "        \n",
    "        print(\"   Image modality:\")\n",
    "        for key, props in image_analysis.items():\n",
    "            print(f\"     {key}: {props['memory_size_bytes']}\")\n",
    "            \n",
    "        print(\"   Audio modality:\")\n",
    "        for key, props in audio_analysis.items():\n",
    "            print(f\"     {key}: {props['memory_size_bytes']}\")\n",
    "        \n",
    "        print(\"\\n2. Data Type Summary:\")\n",
    "        print(\"   Text: String/Unicode (variable length)\")\n",
    "        print(\"   Image: Numerical arrays (fixed dimensions)\")\n",
    "        print(\"   Audio: Numerical arrays (time-series)\")\n",
    "        \n",
    "        print(\"\\n3. Key Characteristics:\")\n",
    "        print(\"   Text:\")\n",
    "        print(\"     - Discrete symbols/tokens\")\n",
    "        print(\"     - Variable length sequences\")\n",
    "        print(\"     - Semantic meaning in combinations\")\n",
    "        print(\"   Image:\")\n",
    "        print(\"     - Continuous pixel values\")\n",
    "        print(\"     - Spatial relationships important\")\n",
    "        print(\"     - Fixed dimensional grids\")\n",
    "        print(\"   Audio:\")\n",
    "        print(\"     - Continuous amplitude values\")\n",
    "        print(\"     - Temporal relationships important\")\n",
    "        print(\"     - Time-series data\")\n",
    "\n",
    "print(\"PART 4: MULTIMODAL DATA COMPARISON\")\n",
    "print(\"=\" * 35)\n",
    "comparison_handler = MultimodalDataComparison()\n",
    "comparison_handler.compare_modalities(text_analysis, image_analysis, audio_analysis)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DEMONSTRATION COMPLETE\")\n",
    "print(\"\\nKey Takeaways:\")\n",
    "print(\"- Each modality has unique data representation characteristics\")\n",
    "print(\"- Memory requirements vary significantly across modalities\")\n",
    "print(\"- Data types and structures differ fundamentally\")\n",
    "print(\"- Understanding these differences is crucial for multimodal AI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "**Foundation for Multimodal AI Understanding**  \n",
    "\n",
    "This comprehensive exploration of multimodal data representation provides essential groundwork for advanced multimodal AI concepts:\n",
    "1. **Data-Driven Design Decisions**  \n",
    "- Understanding the fundamental characteristics of each modality enables informed decisions about:\n",
    "- Architecture design based on data requirements\n",
    "- Memory allocation and computational resource planning\n",
    "- Preprocessing pipeline optimization\n",
    "- Batch size and processing strategy selection\n",
    "2. **Multimodal System Complexity**  \n",
    "- The stark differences between modalities explain why:\n",
    "- Simple concatenation of modalities is often insufficient\n",
    "- Specialized preprocessing pipelines are necessary for each modality\n",
    "- Cross-modal alignment and synchronization are challenging\n",
    "- Multimodal fusion requires sophisticated approaches\n",
    "3. **Engineering Considerations**  \n",
    "- Real-world multimodal systems must address:\n",
    "- Memory management across different data types\n",
    "- Processing pipeline coordination\n",
    "- Quality vs. efficiency trade-offs for each modality\n",
    "- Scalability challenges as data volume increases\n",
    "4. **Research and Development Implications**  \n",
    "- This foundational understanding enables:\n",
    "- Informed evaluation of multimodal AI research papers\n",
    "- Effective debugging of multimodal system issues\n",
    "- Strategic planning for multimodal AI projects\n",
    "- Recognition of fundamental limitations and opportunities\n",
    "  \n",
    "Mastering multimodal data representation is essential for anyone working with AI systems that process multiple types of data. The fundamental differences between text, image, and audio data create both challenges and opportunities in multimodal AI development. This knowledge serves as the critical foundation for understanding more advanced topics like multimodal fusion, cross-modal learning, and multimodal model architectures.\n",
    "By understanding how each modality stores information, consumes resources, and presents unique characteristics, students are prepared to tackle the complex challenges of building AI systems that can effectively process and understand multiple types of data simultaneously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
