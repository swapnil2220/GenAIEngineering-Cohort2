{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook 2: Data Alignment and Synchronization Tutorial\n",
    "==============================================================\n",
    "\n",
    "[Click to view on Google Colab](https://colab.research.google.com/drive/1a4Nb3y8Wz5xt88JKJ_f5bn_nistPAiOb?usp=sharing)    \n",
    "  \n",
    "This tutorial teaches data alignment concepts step by step.\n",
    "We'll start with simple examples and gradually build up complexity.\n",
    "\n",
    "Learning Path:\n",
    "1. Understanding what temporal alignment means\n",
    "2. Simple time-based alignment\n",
    "3. Detecting missing data\n",
    "4. Cross-modal validation basics\n",
    "5. Building a complete alignment system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy matplotlib\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Dict\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python dataclass for segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class SimpleSegment:\n",
    "    \"\"\"A simple segment with start time, end time, and description.\"\"\"\n",
    "    start_time: float\n",
    "    end_time: float\n",
    "    description: str\n",
    "    \n",
    "    def duration(self) -> float:\n",
    "        \"\"\"How long is this segment?\"\"\"\n",
    "        return self.end_time - self.start_time\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"[{self.start_time:.1f}s-{self.end_time:.1f}s]: {self.description}\"\n",
    "    \n",
    "    def __hash__(self):\n",
    "        \"\"\"Make the object hashable so it can be used in sets.\"\"\"\n",
    "        return hash((self.start_time, self.end_time, self.description))\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        \"\"\"Define equality for proper set operations.\"\"\"\n",
    "        if not isinstance(other, SimpleSegment):\n",
    "            return False\n",
    "        return (self.start_time == other.start_time and \n",
    "                self.end_time == other.end_time and \n",
    "                self.description == other.description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Temporal Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step1_understanding_temporal_alignment(verbose=True):\n",
    "    \"\"\"\n",
    "    Step 1: What is temporal alignment?\n",
    "    \n",
    "    Imagine you have a video and captions. Sometimes the captions don't \n",
    "    perfectly match when things happen in the video. Temporal alignment \n",
    "    helps us match them up correctly.\n",
    "    \"\"\"\n",
    "    if verbose:\n",
    "        print(\"=\" * 60)\n",
    "        print(\"STEP 1: Understanding Temporal Alignment\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        print(\"\\nüé¨ Let's say we have a simple video with these scenes:\")\n",
    "    \n",
    "    # Simple video segments\n",
    "    video_segments = [\n",
    "        SimpleSegment(0.0, 3.0, \"Person walks into room\"),\n",
    "        SimpleSegment(3.0, 6.0, \"Person sits down\"),\n",
    "        SimpleSegment(6.0, 9.0, \"Person starts reading\"),\n",
    "    ]\n",
    "    \n",
    "    if verbose:\n",
    "        for i, segment in enumerate(video_segments, 1):\n",
    "            print(f\"   Video {i}: {segment}\")\n",
    "        \n",
    "        print(\"\\nüìù And we have captions that describe what's happening:\")\n",
    "    \n",
    "    # Caption segments (slightly misaligned)\n",
    "    text_segments = [\n",
    "        SimpleSegment(0.5, 3.5, \"Someone enters the room\"),\n",
    "        SimpleSegment(3.2, 6.2, \"The person takes a seat\"),\n",
    "        SimpleSegment(6.1, 9.1, \"Reading begins\"),\n",
    "    ]\n",
    "    \n",
    "    if verbose:\n",
    "        for i, segment in enumerate(text_segments, 1):\n",
    "            print(f\"   Caption {i}: {segment}\")\n",
    "        \n",
    "        print(\"\\nü§î Notice the problem?\")\n",
    "        print(\"   - Video starts at 0.0s, but caption starts at 0.5s\")\n",
    "        print(\"   - There's a small time difference (offset) between video and text\")\n",
    "        print(\"   - This is what we need to 'align' or match up!\")\n",
    "    \n",
    "    return video_segments, text_segments\n",
    "\n",
    "video_segments, text_segments = step1_understanding_temporal_alignment()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step2_simple_alignment():\n",
    "    \"\"\"\n",
    "    Step 2: Let's try a simple alignment method\n",
    "    \n",
    "    We'll use the \"closest in time\" approach - match each video segment\n",
    "    with the text segment that starts closest to it in time.\n",
    "    \n",
    "    Note: This function uses the video_segments and text_segments from Step 1\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"STEP 2: Simple Time-Based Alignment\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    print(\"\\nüîç Let's find the best matches:\")\n",
    "    \n",
    "    alignments = []\n",
    "    \n",
    "    for i, video_seg in enumerate(video_segments):\n",
    "        print(f\"\\n   Looking for match for Video {i+1}: {video_seg}\")\n",
    "        \n",
    "        best_match = None\n",
    "        smallest_time_difference = float('inf')  # Start with a very large number\n",
    "        \n",
    "        for j, text_seg in enumerate(text_segments):\n",
    "            # Calculate how far apart the start times are\n",
    "            time_difference = abs(video_seg.start_time - text_seg.start_time)\n",
    "            print(f\"      Caption {j+1} starts {time_difference:.1f}s away\")\n",
    "            \n",
    "            # Is this the closest match so far?\n",
    "            if time_difference < smallest_time_difference:\n",
    "                smallest_time_difference = time_difference\n",
    "                best_match = (j, text_seg)\n",
    "        \n",
    "        if best_match:\n",
    "            alignments.append({\n",
    "                'video': video_seg,\n",
    "                'text': best_match[1],\n",
    "                'time_offset': smallest_time_difference\n",
    "            })\n",
    "            print(f\"   ‚úÖ Best match: Caption {best_match[0]+1} (offset: {smallest_time_difference:.1f}s)\")\n",
    "    \n",
    "    print(f\"\\nüìä Alignment Results:\")\n",
    "    for i, alignment in enumerate(alignments, 1):\n",
    "        print(f\"   Pair {i}:\")\n",
    "        print(f\"      Video: {alignment['video']}\")\n",
    "        print(f\"      Text:  {alignment['text']}\")\n",
    "        print(f\"      Time difference: {alignment['time_offset']:.1f} seconds\")\n",
    "    \n",
    "    return alignments\n",
    "\n",
    "alignments = step2_simple_alignment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alignment Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step3_visualize_alignment():\n",
    "    \"\"\"\n",
    "    Step 3: Let's visualize what alignment looks like\n",
    "    \n",
    "    A picture is worth a thousand words! Let's draw a timeline.\n",
    "    \n",
    "    Note: This function uses the alignments from Step 2\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"STEP 3: Visualizing Alignment\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Create a simple visualization\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 6))\n",
    "    \n",
    "    # Plot video segments\n",
    "    for i, alignment in enumerate(alignments):\n",
    "        video_seg = alignment['video']\n",
    "        text_seg = alignment['text']\n",
    "        \n",
    "        # Video segments in blue\n",
    "        ax.barh(0, video_seg.duration(), left=video_seg.start_time, \n",
    "                height=0.3, alpha=0.7, color='blue', \n",
    "                label='Video' if i == 0 else \"\")\n",
    "        \n",
    "        # Text segments in green\n",
    "        ax.barh(1, text_seg.duration(), left=text_seg.start_time, \n",
    "                height=0.3, alpha=0.7, color='green',\n",
    "                label='Text' if i == 0 else \"\")\n",
    "        \n",
    "        # Draw connection lines\n",
    "        video_center = video_seg.start_time + video_seg.duration() / 2\n",
    "        text_center = text_seg.start_time + text_seg.duration() / 2\n",
    "        ax.plot([video_center, text_center], [0.15, 0.85], \n",
    "                'r--', alpha=0.5, linewidth=1)\n",
    "    \n",
    "    ax.set_yticks([0, 1])\n",
    "    ax.set_yticklabels(['Video', 'Text'])\n",
    "    ax.set_xlabel('Time (seconds)')\n",
    "    ax.set_title('Temporal Alignment Visualization')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print(\"\\nüìä Alignment visualization displayed above\")\n",
    "\n",
    "step3_visualize_alignment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step4_handling_missing_data():\n",
    "    \"\"\"\n",
    "    Step 4: What happens when data is missing?\n",
    "    \n",
    "    In real life, sometimes we have video without captions, or captions \n",
    "    without video. Let's learn how to handle this.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"STEP 4: Handling Missing Data\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    print(\"\\nüé¨ Let's create a more realistic scenario:\")\n",
    "    \n",
    "    # Video with some segments\n",
    "    video_segments_missing = [\n",
    "        SimpleSegment(0.0, 2.0, \"Opening scene\"),\n",
    "        SimpleSegment(2.0, 5.0, \"Main action\"),\n",
    "        SimpleSegment(5.0, 7.0, \"Dialogue scene\"),\n",
    "        SimpleSegment(7.0, 10.0, \"Closing scene\"),\n",
    "    ]\n",
    "    \n",
    "    # Text with missing segments (notice gaps!)\n",
    "    text_segments_missing = [\n",
    "        SimpleSegment(0.2, 2.2, \"The story begins\"),\n",
    "        # Missing caption for \"Main action\" (2.0-5.0)\n",
    "        SimpleSegment(5.1, 7.1, \"Characters talking\"),\n",
    "        SimpleSegment(7.2, 10.2, \"The end\"),\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nüìπ Video segments:\")\n",
    "    for i, seg in enumerate(video_segments_missing, 1):\n",
    "        print(f\"   {i}. {seg}\")\n",
    "    \n",
    "    print(\"\\nüìù Text segments (notice something missing?):\")\n",
    "    for i, seg in enumerate(text_segments_missing, 1):\n",
    "        print(f\"   {i}. {seg}\")\n",
    "    \n",
    "    print(\"\\nüîç Let's try to align them and see what happens:\")\n",
    "    \n",
    "    alignments_missing = []\n",
    "    unmatched_video = []\n",
    "    text_segments_copy = text_segments_missing.copy()  # Make a copy so we can modify it\n",
    "    \n",
    "    # Try to match each video segment\n",
    "    for video_seg in video_segments_missing:\n",
    "        best_match = None\n",
    "        best_distance = float('inf')\n",
    "        \n",
    "        for text_seg in text_segments_copy:\n",
    "            distance = abs(video_seg.start_time - text_seg.start_time)\n",
    "            if distance < best_distance and distance < 2.0:  # Within 2 seconds\n",
    "                best_distance = distance\n",
    "                best_match = text_seg\n",
    "        \n",
    "        if best_match:\n",
    "            alignments_missing.append({'video': video_seg, 'text': best_match})\n",
    "            # Remove the matched text so it can't be matched again\n",
    "            text_segments_copy.remove(best_match)\n",
    "        else:\n",
    "            unmatched_video.append(video_seg)\n",
    "    \n",
    "    # Any remaining text segments are unmatched\n",
    "    unmatched_text = text_segments_copy\n",
    "    \n",
    "    print(f\"\\n‚úÖ Successfully aligned: {len(alignments_missing)} pairs\")\n",
    "    for i, alignment in enumerate(alignments_missing, 1):\n",
    "        print(f\"   {i}. Video: {alignment['video'].description} ‚Üî Text: {alignment['text'].description}\")\n",
    "    \n",
    "    print(f\"\\n‚ùå Unmatched video segments: {len(unmatched_video)}\")\n",
    "    for seg in unmatched_video:\n",
    "        print(f\"   - {seg}\")\n",
    "    \n",
    "    print(f\"\\n‚ùå Unmatched text segments: {len(unmatched_text)}\")\n",
    "    for seg in unmatched_text:\n",
    "        print(f\"   - {seg}\")\n",
    "    \n",
    "    print(\"\\nüí° Key insights:\")\n",
    "    print(\"   - Not everything can be perfectly aligned\")\n",
    "    print(\"   - Missing data is common in real applications\")\n",
    "    print(\"   - We need strategies to handle unmatched segments\")\n",
    "    \n",
    "    return alignments_missing, unmatched_video, unmatched_text\n",
    "\n",
    "alignments_missing, unmatched_video, unmatched_text = step4_handling_missing_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Modal Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step5_cross_modal_validation():\n",
    "    \"\"\"\n",
    "    Step 5: Cross-modal validation - checking if our alignments make sense\n",
    "    \n",
    "    Just because two segments are close in time doesn't mean they actually \n",
    "    match in content. Let's add some basic validation.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"STEP 5: Cross-Modal Validation\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    print(\"\\nüß† Let's check if our alignments actually make sense...\")\n",
    "    print(\"We'll use simple keyword matching to validate alignments.\")\n",
    "    \n",
    "    # Create test data with some good and bad alignments\n",
    "    video_segments_validation = [\n",
    "        SimpleSegment(0.0, 3.0, \"person walking in park\"),\n",
    "        SimpleSegment(3.0, 6.0, \"dog running and playing\"),\n",
    "        SimpleSegment(6.0, 9.0, \"children on playground\"),\n",
    "    ]\n",
    "    \n",
    "    text_segments_validation = [\n",
    "        SimpleSegment(0.2, 3.2, \"someone walks through the park\"),\n",
    "        SimpleSegment(3.1, 6.1, \"a dog plays energetically\"),\n",
    "        SimpleSegment(6.2, 9.2, \"kids having fun at playground\"),\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nüìπ Video segments:\")\n",
    "    for i, seg in enumerate(video_segments_validation, 1):\n",
    "        print(f\"   {i}. {seg}\")\n",
    "    \n",
    "    print(\"\\nüìù Text segments:\")\n",
    "    for i, seg in enumerate(text_segments_validation, 1):\n",
    "        print(f\"   {i}. {seg}\")\n",
    "    \n",
    "    # Simple alignment based on time\n",
    "    alignments_validation = []\n",
    "    text_segments_copy = text_segments_validation.copy()\n",
    "    \n",
    "    for video_seg in video_segments_validation:\n",
    "        best_match = None\n",
    "        best_distance = float('inf')\n",
    "        \n",
    "        for text_seg in text_segments_copy:\n",
    "            distance = abs(video_seg.start_time - text_seg.start_time)\n",
    "            if distance < best_distance:\n",
    "                best_distance = distance\n",
    "                best_match = text_seg\n",
    "        \n",
    "        alignments_validation.append({\n",
    "            'video': video_seg,\n",
    "            'text': best_match,\n",
    "            'time_distance': best_distance\n",
    "        })\n",
    "        text_segments_copy.remove(best_match)  # Prevent double matching\n",
    "    \n",
    "    print(f\"\\nüîç Now let's validate these alignments using content similarity:\")\n",
    "    \n",
    "    def simple_content_similarity(video_desc: str, text_desc: str) -> float:\n",
    "        \"\"\"\n",
    "        Simple content similarity based on common words.\n",
    "        Returns a score between 0 and 1.\n",
    "        \"\"\"\n",
    "        video_words = set(video_desc.lower().split())\n",
    "        text_words = set(text_desc.lower().split())\n",
    "        \n",
    "        # Find common words\n",
    "        common_words = video_words.intersection(text_words)\n",
    "        total_words = video_words.union(text_words)\n",
    "        \n",
    "        # Calculate similarity (Jaccard similarity)\n",
    "        similarity = len(common_words) / len(total_words) if total_words else 0\n",
    "        return similarity\n",
    "    \n",
    "    validated_alignments = []\n",
    "    \n",
    "    for i, alignment in enumerate(alignments_validation, 1):\n",
    "        video_desc = alignment['video'].description\n",
    "        text_desc = alignment['text'].description\n",
    "        \n",
    "        content_similarity = simple_content_similarity(video_desc, text_desc)\n",
    "        time_quality = 1.0 / (1.0 + alignment['time_distance'])  # Better if closer in time\n",
    "        \n",
    "        # Combined score (you can adjust these weights)\n",
    "        overall_score = 0.7 * content_similarity + 0.3 * time_quality\n",
    "        \n",
    "        alignment['content_similarity'] = content_similarity\n",
    "        alignment['overall_score'] = overall_score\n",
    "        \n",
    "        print(f\"\\n   Alignment {i}:\")\n",
    "        print(f\"      Video: {video_desc}\")\n",
    "        print(f\"      Text:  {text_desc}\")\n",
    "        print(f\"      Time distance: {alignment['time_distance']:.1f}s\")\n",
    "        print(f\"      Content similarity: {content_similarity:.2f}\")\n",
    "        print(f\"      Overall score: {overall_score:.2f}\")\n",
    "        \n",
    "        # Only keep high-quality alignments\n",
    "        if overall_score > 0.3:  # Lower threshold for better demonstration\n",
    "            validated_alignments.append(alignment)\n",
    "            print(f\"      ‚úÖ ACCEPTED\")\n",
    "        else:\n",
    "            print(f\"      ‚ùå REJECTED (low quality)\")\n",
    "    \n",
    "    print(f\"\\nüìä Validation Results:\")\n",
    "    print(f\"   - Original alignments: {len(alignments_validation)}\")\n",
    "    print(f\"   - Validated alignments: {len(validated_alignments)}\")\n",
    "    print(f\"   - Rejection rate: {(len(alignments_validation) - len(validated_alignments)) / len(alignments_validation) * 100:.1f}%\")\n",
    "    \n",
    "    return validated_alignments\n",
    "\n",
    "validated_alignments = step5_cross_modal_validation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Alignment Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step6_complete_alignment_system():\n",
    "    \"\"\"\n",
    "    Step 6: Putting it all together - a complete alignment pipeline\n",
    "    \n",
    "    Now let's combine everything we've learned into a simple but complete\n",
    "    alignment system.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"STEP 6: Complete Alignment Pipeline\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    print(\"\\nüîß Let's build a complete alignment system step by step:\")\n",
    "    \n",
    "    class SimpleAligner:\n",
    "        \"\"\"A simple but complete alignment system for beginners.\"\"\"\n",
    "        \n",
    "        def __init__(self, max_time_distance=2.0, min_content_similarity=0.3):\n",
    "            self.max_time_distance = max_time_distance\n",
    "            self.min_content_similarity = min_content_similarity\n",
    "        \n",
    "        def align(self, video_segments: List[SimpleSegment], \n",
    "                 text_segments: List[SimpleSegment]) -> Dict:\n",
    "            \"\"\"Main alignment function.\"\"\"\n",
    "            \n",
    "            print(f\"üéØ Aligning {len(video_segments)} video segments with {len(text_segments)} text segments\")\n",
    "            \n",
    "            # Step 1: Time-based matching\n",
    "            time_matches = self._find_time_matches(video_segments, text_segments)\n",
    "            print(f\"   Found {len(time_matches)} time-based matches\")\n",
    "            \n",
    "            # Step 2: Content validation\n",
    "            validated_matches = self._validate_content(time_matches)\n",
    "            print(f\"   {len(validated_matches)} matches passed content validation\")\n",
    "            \n",
    "            # Step 3: Identify unmatched segments\n",
    "            unmatched = self._find_unmatched(video_segments, text_segments, validated_matches)\n",
    "            \n",
    "            return {\n",
    "                'alignments': validated_matches,\n",
    "                'unmatched_video': unmatched['video'],\n",
    "                'unmatched_text': unmatched['text'],\n",
    "                'stats': self._calculate_stats(validated_matches, unmatched)\n",
    "            }\n",
    "        \n",
    "        def _find_time_matches(self, video_segments, text_segments):\n",
    "            \"\"\"Find matches based on temporal proximity.\"\"\"\n",
    "            matches = []\n",
    "            available_text = text_segments.copy()\n",
    "            \n",
    "            for video_seg in video_segments:\n",
    "                best_match = None\n",
    "                best_distance = float('inf')\n",
    "                \n",
    "                for text_seg in available_text:\n",
    "                    distance = abs(video_seg.start_time - text_seg.start_time)\n",
    "                    if distance < best_distance and distance <= self.max_time_distance:\n",
    "                        best_distance = distance\n",
    "                        best_match = text_seg\n",
    "                \n",
    "                if best_match:\n",
    "                    matches.append({\n",
    "                        'video': video_seg,\n",
    "                        'text': best_match,\n",
    "                        'time_distance': best_distance\n",
    "                    })\n",
    "                    available_text.remove(best_match)\n",
    "            \n",
    "            return matches\n",
    "        \n",
    "        def _validate_content(self, matches):\n",
    "            \"\"\"Validate matches using content similarity.\"\"\"\n",
    "            validated = []\n",
    "            \n",
    "            for match in matches:\n",
    "                similarity = self._content_similarity(\n",
    "                    match['video'].description, \n",
    "                    match['text'].description\n",
    "                )\n",
    "                \n",
    "                if similarity >= self.min_content_similarity:\n",
    "                    match['content_similarity'] = similarity\n",
    "                    validated.append(match)\n",
    "            \n",
    "            return validated\n",
    "        \n",
    "        def _content_similarity(self, video_desc, text_desc):\n",
    "            \"\"\"Simple content similarity calculation.\"\"\"\n",
    "            video_words = set(video_desc.lower().split())\n",
    "            text_words = set(text_desc.lower().split())\n",
    "            \n",
    "            common = video_words.intersection(text_words)\n",
    "            total = video_words.union(text_words)\n",
    "            \n",
    "            return len(common) / len(total) if total else 0\n",
    "        \n",
    "        def _find_unmatched(self, video_segments, text_segments, matches):\n",
    "            \"\"\"Find segments that couldn't be matched.\"\"\"\n",
    "            matched_video = set()\n",
    "            matched_text = set()\n",
    "            \n",
    "            for match in matches:\n",
    "                matched_video.add(match['video'])\n",
    "                matched_text.add(match['text'])\n",
    "            \n",
    "            return {\n",
    "                'video': [seg for seg in video_segments if seg not in matched_video],\n",
    "                'text': [seg for seg in text_segments if seg not in matched_text]\n",
    "            }\n",
    "        \n",
    "        def _calculate_stats(self, matches, unmatched):\n",
    "            \"\"\"Calculate alignment statistics.\"\"\"\n",
    "            total_video = len(matches) + len(unmatched['video'])\n",
    "            total_text = len(matches) + len(unmatched['text'])\n",
    "            \n",
    "            return {\n",
    "                'alignment_rate': len(matches) / total_video if total_video > 0 else 0,\n",
    "                'avg_time_distance': np.mean([m['time_distance'] for m in matches]) if matches else 0,\n",
    "                'avg_content_similarity': np.mean([m['content_similarity'] for m in matches]) if matches else 0\n",
    "            }\n",
    "    \n",
    "    # Test our complete system\n",
    "    print(f\"\\nüß™ Testing our complete alignment system:\")\n",
    "    \n",
    "    # Create test data\n",
    "    video_segments_final = [\n",
    "        SimpleSegment(0.0, 3.0, \"person walking dog\"),\n",
    "        SimpleSegment(3.5, 6.0, \"dog playing fetch\"),\n",
    "        SimpleSegment(7.0, 10.0, \"people sitting park\"),\n",
    "        SimpleSegment(11.0, 14.0, \"children playground\"),\n",
    "    ]\n",
    "    \n",
    "    text_segments_final = [\n",
    "        SimpleSegment(0.2, 3.2, \"someone walks their dog\"),\n",
    "        SimpleSegment(3.7, 6.2, \"dog plays with ball\"),\n",
    "        SimpleSegment(7.1, 10.1, \"people relaxing in park\"),\n",
    "        # Missing text for children playground\n",
    "        SimpleSegment(15.0, 18.0, \"birds flying overhead\"),  # Extra text\n",
    "    ]\n",
    "    \n",
    "    # Run alignment\n",
    "    aligner = SimpleAligner(max_time_distance=1.0, min_content_similarity=0.1)  # Lower threshold\n",
    "    results = aligner.align(video_segments_final, text_segments_final)\n",
    "    \n",
    "    # Display results\n",
    "    print(f\"\\nüìä Final Results:\")\n",
    "    print(f\"   ‚úÖ Successful alignments: {len(results['alignments'])}\")\n",
    "    for i, alignment in enumerate(results['alignments'], 1):\n",
    "        print(f\"      {i}. Video: {alignment['video'].description}\")\n",
    "        print(f\"         Text:  {alignment['text'].description}\")\n",
    "        print(f\"         Time offset: {alignment['time_distance']:.1f}s\")\n",
    "        print(f\"         Content similarity: {alignment['content_similarity']:.2f}\")\n",
    "    \n",
    "    print(f\"\\n   ‚ùå Unmatched video: {len(results['unmatched_video'])}\")\n",
    "    for seg in results['unmatched_video']:\n",
    "        print(f\"      - {seg}\")\n",
    "    \n",
    "    print(f\"\\n   ‚ùå Unmatched text: {len(results['unmatched_text'])}\")\n",
    "    for seg in results['unmatched_text']:\n",
    "        print(f\"      - {seg}\")\n",
    "    \n",
    "    stats = results['stats']\n",
    "    print(f\"\\n   üìà Statistics:\")\n",
    "    print(f\"      - Alignment rate: {stats['alignment_rate']:.1%}\")\n",
    "    print(f\"      - Average time distance: {stats['avg_time_distance']:.2f}s\")\n",
    "    print(f\"      - Average content similarity: {stats['avg_content_similarity']:.2f}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "final_results = step6_complete_alignment_system()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gs_w7_s1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
