{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smart Food Image Generator - Assignment\n",
    "\n",
    "[View on Google Colab](https://colab.research.google.com/drive/1Hwv2LPI8CGO7pNfTaA462e4Ywkht_NkC?usp=sharing)\n",
    "\n",
    "Week 8: Multimodal AI for Food Delivery Business\n",
    "\n",
    "OBJECTIVE: Build an AI system that can generate professional food images \n",
    "and analyze them for safety using Stable Diffusion and BLIP models.\n",
    "\n",
    "LEARNING GOALS:\n",
    "- Use Stable Diffusion for text-to-image generation\n",
    "- Use BLIP VQA for food analysis and safety detection\n",
    "- Combine multiple AI models for practical food delivery applications\n",
    "- Build a complete food generation and analysis pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from transformers import BlipProcessor, BlipForQuestionAnswering\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_device():\n",
    "    \"\"\"\n",
    "    Setup device for optimal performance\n",
    "    \n",
    "    SOLUTION: Check for available hardware and return appropriate device and data type.\n",
    "    \"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return \"cuda\", torch.float16\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return \"mps\", torch.float32\n",
    "    else:\n",
    "        return \"cpu\", torch.float32\n",
    "\n",
    "# TEST: Setup device\n",
    "print(\"üîß TESTING: Setting up device...\")\n",
    "device, dtype = setup_device()\n",
    "print(f\"Using device: {device}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models(device, dtype):\n",
    "    \"\"\"\n",
    "    Load all required models for food generation and analysis\n",
    "    \n",
    "    TODO: Load Stable Diffusion and BLIP models\n",
    "    HINT: Use the model loading patterns from Week8 notebooks\n",
    "    HINT: Use 'global' keyword to modify global variables\n",
    "    \n",
    "    MODELS TO LOAD:\n",
    "    - Stable Diffusion: \"runwayml/stable-diffusion-v1-5\"\n",
    "    - BLIP VQA: \"Salesforce/blip-vqa-base\"\n",
    "    \n",
    "    Args:\n",
    "        device: Device to load models on\n",
    "        dtype: Data type for models\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (text2img_pipeline, blip_model, blip_processor)\n",
    "    \"\"\"\n",
    "    global text2img_pipe, blip_model, blip_processor\n",
    "    \n",
    "    print(\"üì¶ Loading models...\")\n",
    "    \n",
    "    # TODO: Load Stable Diffusion pipeline\n",
    "    # text2img_pipe = ?\n",
    "    # text2img_pipe = text2img_pipe.to(device)\n",
    "    \n",
    "    # TODO: Load BLIP VQA model and processor\n",
    "    # blip_model = ?\n",
    "    # blip_processor = ?\n",
    "    # blip_model.eval()\n",
    "    \n",
    "    # DUMMY IMPLEMENTATION (Remove this when implementing)\n",
    "    print(\"‚ö†Ô∏è DUMMY: Models not loaded yet - implement the TODO sections above\")\n",
    "    \n",
    "    print(\"‚úÖ All models loaded successfully!\")\n",
    "    return text2img_pipe, blip_model, blip_processor\n",
    "\n",
    "# TEST: Load models\n",
    "print(\"üì¶ TESTING: Loading models...\")\n",
    "text2img_pipe, blip_model, blip_processor = load_models(device, dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Food Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_food_image(food_description, seed=42):\n",
    "    \"\"\"\n",
    "    Generate professional food image from text description\n",
    "    \n",
    "    TODO: Implement food image generation using Stable Diffusion\n",
    "    HINT: Enhance the prompt with food photography terms\n",
    "    HINT: Use negative prompts to avoid unappetizing results\n",
    "    HINT: Set seed for reproducible results\n",
    "    \n",
    "    Args:\n",
    "        food_description (str): Description of food to generate\n",
    "        seed (int): Random seed for reproducibility\n",
    "        \n",
    "    Returns:\n",
    "        PIL.Image: Generated food image\n",
    "        \n",
    "    EXAMPLE INPUT: \"butter chicken with rice and naan\"\n",
    "    EXAMPLE OUTPUT: PIL Image of appetizing butter chicken dish\n",
    "    \"\"\"\n",
    "    print(f\"üçΩÔ∏è Generating: {food_description}\")\n",
    "    \n",
    "    # TODO: Enhance prompt for better food photography\n",
    "    # prompt = f\"{food_description}, professional food photography, appetizing, restaurant style\"\n",
    "    \n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "    \n",
    "    # TODO: Generate image using Stable Diffusion\n",
    "    # with torch.no_grad():\n",
    "    #     result = ?\n",
    "    \n",
    "    # TODO: Return the generated image\n",
    "    # return result.images[0]\n",
    "    \n",
    "    # DUMMY IMPLEMENTATION (Remove this when implementing)\n",
    "    print(\"‚ö†Ô∏è DUMMY: Would generate food image here\")\n",
    "    # Create a dummy image for testing\n",
    "    dummy_image = Image.new('RGB', (512, 512), color='lightblue')\n",
    "    return dummy_image\n",
    "\n",
    "# TEST: Generate food image\n",
    "print(\"üçΩÔ∏è TESTING: Generating food image...\")\n",
    "test_food = \"butter chicken with rice and naan\"\n",
    "food_image = generate_food_image(test_food)\n",
    "\n",
    "# Display the image\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(food_image)\n",
    "plt.title(f\"Generated: {test_food}\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question Answering about Food"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_about_food(image, question):\n",
    "    \"\"\"\n",
    "    Ask questions about food using BLIP VQA\n",
    "    \n",
    "    TODO: Implement visual question answering using BLIP\n",
    "    HINT: Process image and question, then generate answer\n",
    "    HINT: Use the global blip_model and blip_processor\n",
    "    \n",
    "    Args:\n",
    "        image (PIL.Image): Food image to analyze\n",
    "        question (str): Question to ask about the food\n",
    "        \n",
    "    Returns:\n",
    "        str: Answer to the question\n",
    "        \n",
    "    EXAMPLE INPUT: \n",
    "        image = <PIL Image of curry>\n",
    "        question = \"Does this contain dairy?\"\n",
    "        \n",
    "    EXAMPLE OUTPUT: \"yes\"\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO: Process image and question using BLIP\n",
    "    # inputs = ?\n",
    "    \n",
    "    # TODO: Generate answer\n",
    "    # with torch.no_grad():\n",
    "    #     out = ?\n",
    "    \n",
    "    # TODO: Decode and return answer\n",
    "    # answer = ?\n",
    "    # return answer.strip()\n",
    "    \n",
    "    # DUMMY IMPLEMENTATION (Remove this when implementing)\n",
    "    print(f\"‚ö†Ô∏è DUMMY: Would answer '{question}' about the food\")\n",
    "    return \"unknown\"\n",
    "\n",
    "# TEST: Ask questions about food\n",
    "print(\"‚ùì TESTING: Asking questions about food...\")\n",
    "questions = [\n",
    "    \"What type of food is this?\",\n",
    "    \"Does this contain dairy?\",\n",
    "    \"Is this food spicy?\"\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    answer = ask_about_food(food_image, question)\n",
    "    print(f\"Q: {question}\")\n",
    "    print(f\"A: {answer}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Food Safety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_food_safety(food_image):\n",
    "    \"\"\"\n",
    "    Analyze food for ingredients and allergens\n",
    "    \n",
    "    TODO: Implement comprehensive food safety analysis\n",
    "    HINT: Ask specific questions about allergens and dietary info\n",
    "    HINT: Check for common allergens: dairy, nuts, eggs, gluten\n",
    "    \n",
    "    Args:\n",
    "        food_image (PIL.Image): Food image to analyze\n",
    "        \n",
    "    Returns:\n",
    "        dict: Analysis results with description, allergens, and dietary info\n",
    "        \n",
    "    EXAMPLE OUTPUT: {\n",
    "        \"description\": \"butter chicken with rice\",\n",
    "        \"allergens\": [\"dairy\", \"gluten\"],\n",
    "        \"vegetarian\": \"no\",\n",
    "        \"spicy\": \"yes\"\n",
    "    }\n",
    "    \"\"\"\n",
    "    print(\"üî¨ Analyzing food safety...\")\n",
    "    \n",
    "    # Get basic info\n",
    "    description = ask_about_food(food_image, \"What type of food is this?\")\n",
    "    \n",
    "    # Check for common allergens\n",
    "    # allergen_questions = [\n",
    "    #     \"Does this contain dairy or milk?\",\n",
    "    #     \"Does this contain nuts?\", \n",
    "    # ]\n",
    "    \n",
    "    # allergens = []\n",
    "    # for question in allergen_questions:\n",
    "    #     answer = ask_about_food(food_image, question)\n",
    "    #     if \"yes\" in answer.lower():\n",
    "    #         allergen = question.split(\"contain \")[-1].split(\"?\")[0]\n",
    "    #         allergens.append(allergen)\n",
    "    \n",
    "    # TODO: Get dietary information\n",
    "    # vegetarian = ask_about_food(food_image, ?)\n",
    "    # spicy = ask_about_food(food_image, ?)\n",
    "    \n",
    "    # TODO: Compile analysis results\n",
    "    # analysis = {\n",
    "    #     \"description\": description,\n",
    "    #     \"allergens\": allergens,\n",
    "    #     \"vegetarian\": vegetarian,\n",
    "    #     \"spicy\": spicy\n",
    "    # }\n",
    "    \n",
    "    # DUMMY IMPLEMENTATION (Remove this when implementing)\n",
    "    analysis = {\n",
    "        \"description\": \"unknown food\",\n",
    "        \"allergens\": [],\n",
    "        \"vegetarian\": \"unknown\",\n",
    "        \"spicy\": \"unknown\"\n",
    "    }\n",
    "    print(\"‚ö†Ô∏è DUMMY: Returning fake analysis results\")\n",
    "    \n",
    "    print(\"‚úÖ Food analysis complete!\")\n",
    "    return analysis\n",
    "\n",
    "# TEST: Analyze food safety\n",
    "print(\"üî¨ TESTING: Food safety analysis...\")\n",
    "analysis = analyze_food_safety(food_image)\n",
    "\n",
    "print(\"Analysis Results:\")\n",
    "print(f\"Description: {analysis['description']}\")\n",
    "print(f\"Allergens: {', '.join(analysis['allergens']) if analysis['allergens'] else 'None detected'}\")\n",
    "print(f\"Vegetarian: {analysis['vegetarian']}\")\n",
    "print(f\"Spicy: {analysis['spicy']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate and Analyze Food"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_analyze_food(food_description):\n",
    "    \"\"\"\n",
    "    Complete pipeline: generate food image and analyze it\n",
    "    \n",
    "    TODO: Implement the complete food generation and analysis pipeline\n",
    "    HINT: Combine image generation with safety analysis\n",
    "    HINT: Display results in a side-by-side format\n",
    "    \n",
    "    Args:\n",
    "        food_description (str): Description of food to generate and analyze\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (generated_image, analysis_results)\n",
    "        \n",
    "    PIPELINE STEPS:\n",
    "    1. Generate food image using generate_food_image()\n",
    "    2. Analyze the food using analyze_food_safety()\n",
    "    3. Display results with image and analysis side-by-side\n",
    "    4. Return both image and analysis\n",
    "    \"\"\"\n",
    "    print(f\"üöÄ Complete pipeline for: {food_description}\")\n",
    "    \n",
    "    # TODO: Step 1 - Generate food image\n",
    "    # food_image = generate_food_image(?)\n",
    "    \n",
    "    # TODO: Step 2 - Analyze the food\n",
    "    # analysis = analyze_food_safety(?)\n",
    "    \n",
    "    # TODO: Step 3 - Display results\n",
    "    # fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    # # Show image\n",
    "    # ax1.imshow(food_image)\n",
    "    # ax1.set_title(f\"Generated: {food_description}\")\n",
    "    # ax1.axis('off')\n",
    "    \n",
    "    # # Show analysis\n",
    "    # ax2.axis('off')\n",
    "    # analysis_text = f\"FOOD ANALYSIS\\n\\n\"\n",
    "    # analysis_text += f\"Description: {analysis['description']}\\n\\n\"\n",
    "    # analysis_text += f\"Allergens: {', '.join(analysis['allergens']) if analysis['allergens'] else 'None detected'}\\n\\n\"\n",
    "    # analysis_text += f\"Vegetarian: {analysis['vegetarian']}\\n\"\n",
    "    # analysis_text += f\"Spicy: {analysis['spicy']}\"\n",
    "    \n",
    "    # ax2.text(0.1, 0.9, analysis_text, transform=ax2.transAxes, \n",
    "    #          fontsize=10, verticalalignment='top',\n",
    "    #          bbox=dict(boxstyle=\"round,pad=0.5\", facecolor=\"lightblue\", alpha=0.8))\n",
    "    \n",
    "    # plt.tight_layout()\n",
    "    # plt.show()\n",
    "    \n",
    "    # TODO: Step 4 - Return results\n",
    "    # return food_image, analysis\n",
    "    \n",
    "    # DUMMY IMPLEMENTATION (Remove this when implementing)\n",
    "    print(\"‚ö†Ô∏è DUMMY: Would run complete pipeline here\")\n",
    "    dummy_image = Image.new('RGB', (512, 512), color='lightgreen')\n",
    "    dummy_analysis = {\"description\": \"test food\", \"allergens\": [], \"vegetarian\": \"unknown\", \"spicy\": \"unknown\"}\n",
    "    \n",
    "    # Simple display for dummy\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.imshow(dummy_image)\n",
    "    plt.title(f\"DUMMY: {food_description}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    return dummy_image, dummy_analysis\n",
    "\n",
    "# TEST: Complete pipeline\n",
    "print(\"üöÄ TESTING: Complete pipeline...\")\n",
    "test_foods = [\n",
    "    \"chocolate chip cookies\",\n",
    "    \"grilled salmon with vegetables\"\n",
    "]\n",
    "\n",
    "for food in test_foods:\n",
    "    print(f\"\\n--- Testing: {food} ---\")\n",
    "    img, result = generate_and_analyze_food(food)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
