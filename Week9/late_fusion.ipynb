{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimal Late Fusion Example with Paired Multimodal Data (Flickr8k)\n",
    "  \n",
    "[View on Google Colab](https://colab.research.google.com/drive/1F9Tek26MLHys1uE5s9YFTzDqcjgwVA63?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch datasets transformers\n",
    "# !pip install \"numpy<2.0.0\"\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModel, AutoImageProcessor\n",
    "\n",
    "# For transformers specific warnings\n",
    "import transformers\n",
    "transformers.logging.set_verbosity_error()\n",
    "\n",
    "# For datasets warnings\n",
    "import datasets\n",
    "datasets.logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Dataset from HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_flickr8k_samples(num_samples=5):\n",
    "    \"\"\"\n",
    "    Loads image-caption pairs from the Flickr8k dataset.\n",
    "\n",
    "    Args:\n",
    "        num_samples (int): Number of samples to load.\n",
    "\n",
    "    Returns:\n",
    "        images (list of PIL.Image): Images.\n",
    "        captions (list of str): Corresponding captions.\n",
    "    \"\"\"\n",
    "\n",
    "    ds = load_dataset(\"jxie/flickr8k\", split=\"train\")\n",
    "    ds = ds.select(range(num_samples))\n",
    "    \n",
    "    images, captions = [], []\n",
    "    for sample in ds:\n",
    "        image = sample[\"image\"]\n",
    "        caption = sample[\"caption_0\"]\n",
    "        images.append(image)\n",
    "        captions.append(caption)\n",
    "    return images, captions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, captions = load_flickr8k_samples()\n",
    "print(f\"Loaded {len(images)} image-caption pairs\")\n",
    "print(f\"Captions: {captions}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Image Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_embeddings(texts, model_name=\"sentence-transformers/all-MiniLM-L6-v2\"):\n",
    "    \"\"\"\n",
    "    Get text embeddings using a Hugging Face model.\n",
    "\n",
    "    Args:\n",
    "        texts (list of str): Input texts.\n",
    "        model_name (str): Hugging Face model name.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Embedding matrix.\n",
    "    \"\"\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModel.from_pretrained(model_name)\n",
    "    inputs = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        embeddings = outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_embeds = get_text_embeddings(captions)\n",
    "print(\"Text embeddings shape:\", text_embeds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_embeddings(images, model_name=\"google/vit-base-patch16-224\"):\n",
    "    \"\"\"\n",
    "    Get image embeddings using a Hugging Face vision model.\n",
    "\n",
    "    Args:\n",
    "        images (list of PIL.Image): Input images.\n",
    "        model_name (str): Hugging Face model name.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Embedding matrix.\n",
    "    \"\"\"\n",
    "    processor = AutoImageProcessor.from_pretrained(model_name)\n",
    "    model = AutoModel.from_pretrained(model_name)\n",
    "    inputs = processor(images, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_embeds = get_image_embeddings(images)\n",
    "print(\"Image embeddings shape:\", image_embeds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dummy Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_dummy_classifier(embeddings):\n",
    "    \"\"\"\n",
    "    Dummy classifier for text: returns sigmoid-based scores between 0 and 1.\n",
    "\n",
    "    Args:\n",
    "        embeddings (np.ndarray): Text embedding matrix.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Scores in [0, 1], rounded to 2 decimals.\n",
    "    \"\"\"\n",
    "    means = embeddings.mean(axis=1)\n",
    "    # Scale and add some variation for demonstration\n",
    "    scaled_means = means * 10 + np.random.normal(0, 0.5, len(means))\n",
    "    scores = 1 / (1 + np.exp(-scaled_means))  # Sigmoid function\n",
    "    return np.round(scores, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_dummy_classifier(embeddings):\n",
    "    \"\"\"\n",
    "    Dummy classifier for images: returns sigmoid-based scores between 0 and 1.\n",
    "\n",
    "    Args:\n",
    "        embeddings (np.ndarray): Image embedding matrix.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Scores in [0, 1], rounded to 2 decimals.\n",
    "    \"\"\"\n",
    "    means = embeddings.mean(axis=1)\n",
    "    # Scale and add some variation for demonstration\n",
    "    scaled_means = means * 15 + np.random.normal(0, 0.8, len(means))\n",
    "    scores = 1 / (1 + np.exp(-scaled_means))  # Sigmoid function\n",
    "    return np.round(scores, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_scores = text_dummy_classifier(text_embeds)\n",
    "image_scores = image_dummy_classifier(image_embeds)\n",
    "print(\"Text scores:\", text_scores)\n",
    "print(\"Image scores:\", image_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement Late Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def late_fusion(scores, weights, threshold=0.4):\n",
    "    \"\"\"\n",
    "    Weighted sum fusion with detailed calculation display and binary classification.\n",
    "\n",
    "    Args:\n",
    "        scores (list of np.ndarray): List of score arrays.\n",
    "        weights (list of float): List of weights.\n",
    "        threshold (float): Threshold for binary classification (default 0.4).\n",
    "\n",
    "    Returns:\n",
    "        tuple: (fused_scores, binary_labels) both rounded/formatted appropriately.\n",
    "    \"\"\"\n",
    "    text_scores, image_scores = scores\n",
    "    text_weight, image_weight = weights\n",
    "    \n",
    "    print(\"\\nDetailed fusion calculation:\")\n",
    "    print(\"Sample | Text Score | Image Score | Text*Weight | Image*Weight | Fused Score | Label\")\n",
    "    print(\"-\" * 85)\n",
    "    \n",
    "    fused_scores = []\n",
    "    binary_labels = []\n",
    "    \n",
    "    for i in range(len(text_scores)):\n",
    "        text_weighted = text_scores[i] * text_weight\n",
    "        image_weighted = image_scores[i] * image_weight\n",
    "        fused = text_weighted + image_weighted\n",
    "        fused_scores.append(fused)\n",
    "        \n",
    "        # Binary classification based on threshold\n",
    "        label = \"A\" if fused >= threshold else \"B\"\n",
    "        binary_labels.append(label)\n",
    "        \n",
    "        print(f\"   {i}   |    {text_scores[i]:.2f}    |     {image_scores[i]:.2f}     |    {text_weighted:.2f}     |     {image_weighted:.2f}     |    {fused:.2f}     |   {label}\")\n",
    "    \n",
    "    return np.round(np.array(fused_scores), 2), binary_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fused_scores, labels = late_fusion([text_scores, image_scores], [0.5, 0.5])\n",
    "print(f\"\\nFused scores: {fused_scores}\")\n",
    "print(f\"Binary labels: {labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data model\n",
    "\n",
    "# hardware - CPU, GPU\n",
    "\n",
    "# data/model -> CPU -> GPU\n",
    "# outputs -> GPU\n",
    "\n",
    "# outputs -> GPU -> CPU\n",
    "\n",
    "# array (GPU) -> array.cpu() (CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
